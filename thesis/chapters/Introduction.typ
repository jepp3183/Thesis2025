#import "../lib.typ": *

= Introduction
// V briefly introduce XAI, CFs, supervised vs. unsupervised
// V K-means, not other methods
// V supervised methods: dice, baycon
// V unsupervised: baycon w. soft-scoring, CFClust
// V changing clusters due to a CF, which interpretation?
// V make sure to highlight our contributions!
// V GradCF, Heuristic-based iterative methods, tree-based
// V experiments: 4 datasets, random problem instances, many metrics
// V evaluate baselines and novel
// V evaluate novels between each other
// V good visualizations

With the rapid growth of the machine learning and artificial intelligence (AI) fields, the need for transparency in models has only become more apparent. As more advanced models are seeing real-life use in critical fields like healthcare, the need for end-users to trust the models is also becoming increasingly clear. Similarly, developers require insight into the models in order to improve performance, reduce harmful bias, and comply with increasing regulations. For these reasons, various methods have been proposed for explaining black-box models, under the general field of explainable AI (XAI). 

In this thesis, we explore counterfactual (CF) explanations, which is a specific type of localized explanation for a given model. They explain a single data point, which we call the instance $x$, by providing an alternative point $x'$ which is similar to $x$, but achieves a different outcome. In a supervised setting, this outcome would be a different classification than $x$, but in an unsupervised clustering setting, the alternative outcome would mean it belongs to a different cluster. Within this framework, there is a large variety of methods for defining what characterizes a "good" counterfactual. For example, it may be quantified using the similarity between $x$ and $x'$, or by the sparsity, which is measured using the number of identical features between $x$ and $x'$. We present multiple different metrics, and explore how they interact by identifying potential trade-offs and patterns.

With the counterfactual explanations outlined above, we further narrow the focus of this thesis towards CF generation methods for an unsupervised setting, namely centroid-based clusterings obtained by the $k$-means algorithm. Thus, the main problem we seek to solve is the following: given a clustering $C_0,...,C_(k-1)$, an instance $x$, and a target cluster $C_"target"$, generate a point $x'$ belonging to $C_"target"$ such that the difference between $x$ and $x'$ is small. Again, there are various ways to define this difference, which we explore through researching existing methods and experimentation. Additionally, $k$-means clustering has the property that applying the counterfactual i.e. removing $x$ and adding $x'$ to the data, will change the cluster centers, and thereby the boundaries. We investigate this phenomenon through two new metrics: invalidation, which measures how often a valid CF is invalidated by the change above, and correction, which measures how often an invalid CF is validated. We give a detailed overview of the XAI field and counterfactual explanations in @sec:XAI. We give a brief introduction to $k$-means clustering and the main algorithm for solving it in @sec:kmeans_clustering, and analyze $k$-means counterfactuals in @sec:kmeans_cluster_change.

Given that the field of XAI is relatively new, not much research has been done regarding the subject of CF generation for clustering. For this reason, we first investigate some of the existing methods for supervised models, and try to adapt them to the clustering task. This is done by creating a baseline model which first trains a classifier on the cluster labels, and then applies the supervised counterfactual generation method. We focus on two popular supervised methods, which are detailed further in @sec:supervised_methods: DiCE @mothilalExplainingMachineLearning2020, which tries to generate multiple diverse counterfactuals for a single instance, and BayCon @romashovBayConModelagnosticBayesian2022, which uses Bayesian optimization to maximize an objective function. Additionally, we have identified two existing methods for generating counterfactuals in an unsupervised setting. The first is an adaptation of BayCon @spagnolCounterfactualExplanationsClustering2024, which uses a soft scoring technique to guide the search towards the target cluster. The second, CFClust @vardakasCounterfactualExplanationsKmeans2025, is a brand new method which uses an objective that can be optimized directly and without iterative methods. For CFClust, the implementation by the authors is still a work in progress and has not yet been released publicly, so we have not included it in the experiments. We provide further detail of the unsupervised methods in @sec:unsupervised_counterfactual_methods.

Our contribution to the field of CF generation for clustering consists of 4 new approaches, all of which are introduced and detailed in @sec:novel_methods:
- *Gradient-based counterfactual search (GradCF)* defines a simple objective function based on the similarity of $x$ and $x'$ and on the distance towards the target center $c_"target"$. It then uses gradient descent to efficiently optimize this function and return a single highly plausible counterfactual.
- *Counterfactual Ascent (CFAE)* executes an iterative, heuristics-based search starting from the instance $x$. In each iteration, it randomly samples a point from the target cluster and greedily changes a feature of $x$ to the feature value from the sampled point, moving it towards the cluster boundary with a speed dictated by a learning rate. It aims to achieve high sparsity by punishing changes to features which have not yet been modified. Due to the sampling property, it can generate a user-defined number of counterfactuals by running the algorithm multiple times.
- *Neighbor Counterfactual Search (NeCS)* first finds the $k$-nearest neighbors of $x$ in the target cluster. For each of these, it greedily swaps features until it reaches the target cluster. Thus, it generates $k$ counterfactuals close to the cluster boundary, which should be highly similar to the original instance $x$.
- *Tree-Guided Counterfactuals (TGCF)* first trains any decision tree algorithm on the clustering. It then identifies the leaf in which $x$ is located, and leaves that represent the target cluster. The algorithm then traverses the tree starting from the first common ancestor, and changes features of $x$ based on each inner node's threshold in order to create a counterfactual for each target leaf. To improve performance, we present a post-processing algorithm for the tree which adds more splits in order to encapsulate the clusters more tightly, yielding higher validity. Depending on the complexity of the tree, this method should generate counterfactuals with high sparsity.

In order to evaluate the existing methods and compare them to our contributions, we present experiments on 4 datasets: Iris @iris_53, Wine @wine_109, Breast Cancer @williamwolbergBreastCancerWisconsin1993, and a synthetic 2D dataset. We generate counterfactuals for 100 random instances and targets, and compare each method based on a wide range of metrics. We evaluate the contributed methods in detail, comparing different variations of each and deciding the best parameters. Finally, we compare each of the novel methods against each other in order to find their strength and weaknesses. We present multiple visualizations to gain a deep understanding of each algorithm's properties. The complete experimentation process and results are presented in @sec:experiments.



